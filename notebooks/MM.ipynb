{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fbd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from IPython.display import display, Markdown\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/martina.megasari/workspace/wids_datathon/data/widsdatathon2023/train_data.csv\")\n",
    "df_test = pd.read_csv(\"/Users/martina.megasari/workspace/wids_datathon/data/widsdatathon2023/test_data.csv\")\n",
    "print(f\"df shape:{df.shape}\")\n",
    "print(f\"df_test shape:{df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2bae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5cb62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"startdate\"] = pd.to_datetime(df[\"startdate\"])\n",
    "df[\"startdate\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee3db7",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabcf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df.isna().sum(axis=0)\n",
    "df_missing[df_missing > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769dca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_missing_values = [\n",
    "    \"nmme0-tmp2m-34w__ccsm30\",\n",
    "    \"nmme-tmp2m-56w__ccsm3\",\n",
    "    \"nmme-prate-34w__ccsm3\",\n",
    "    \"nmme0-prate-56w__ccsm30\",\n",
    "    \"nmme0-prate-34w__ccsm30\",\n",
    "    \"nmme-prate-56w__ccsm3\",\n",
    "    \"nmme-tmp2m-34w__ccsm3\",\n",
    "    \"ccsm30\"]\n",
    "cols_missing_values_with_date = cols_missing_values.copy()\n",
    "cols_missing_values_with_date.append(\"startdate\")\n",
    "df.loc[df[cols_missing_values].isna().any(axis=1), cols_missing_values_with_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5329935",
   "metadata": {},
   "source": [
    "There seem to be some pattern in the missing values. When nmme-tmp2m-56w__ccsm3 is NaN, nmme0-prate-56w__ccsm30, nmme-prate-56w__ccsm3, ccsm30 are also NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd962c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"month\"] = df[\"startdate\"].dt.month\n",
    "df[\"year\"] = df[\"startdate\"].dt.year\n",
    "for col in cols_missing_values:\n",
    "    display(\n",
    "        df.loc[df[col].isna(), [col,\"year\",\"month\"]].drop_duplicates()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regardless of the pattern, 2016 doesn't have any missing values. \n",
    "# So it's very likely just some missing measurements. \n",
    "# Let's follow the community to use forward fill.\n",
    "df = df.sort_values([\"lat\",\"lon\",\"startdate\"]).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â remove useless index\n",
    "df = df.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5544d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff = df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e864a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax = sns.heatmap(corr_coeff)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f48e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coeff.loc[target].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a30a9",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant\n",
    "current_date = date.today()\n",
    "current_year = current_date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ae876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "    # constant\n",
    "    current_date = date.today()\n",
    "    current_year = current_date.year\n",
    "    \n",
    "    df[\"startdate\"] = pd.to_datetime(df[\"startdate\"], format=\"%m/%d/%y\")\n",
    "    df[\"year\"] = df[\"startdate\"].dt.year - current_year\n",
    "    df[\"month\"] = df[\"startdate\"].dt.month\n",
    "    df[\"day\"] = df[\"startdate\"].dt.day\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12)\n",
    "    df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12)\n",
    "    df[\"day_sin\"] = np.sin(2*np.pi*df[\"startdate\"].dt.dayofyear/365)\n",
    "    df[\"day_cos\"] = np.cos(2*np.pi*df[\"startdate\"].dt.dayofyear/365)\n",
    "\n",
    "    df_climate = pd.get_dummies(df[\"climateregions__climateregion\"], drop_first=True, prefix=\"climate_region\")\n",
    "    df = pd.concat([df, df_climate], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39579874",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=\"contest-tmp2m-14d__tmp2m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv(df, features, target, params, num_boost_round=100, n_folds=5):\n",
    "    random_state = 13\n",
    "    folds = KFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    scores = []\n",
    "    for idx, (train_idx, val_idx) in enumerate(folds.split(df[features], df[target])):\n",
    "    #     print(train_idx)\n",
    "        X_train = df.loc[train_idx, features]\n",
    "        y_train = df.loc[train_idx, target]\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "        X_val = df.loc[val_idx, features]\n",
    "        y_val = df.loc[val_idx, target]\n",
    "        val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "        model = lgb.train(params=params, train_set=train_data, num_boost_round=num_boost_round, valid_sets=[train_data, val_data])\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        scores.append(mean_squared_error(y_val_pred, y_val))\n",
    "    return scores\n",
    "\n",
    "def create_submission(df_test, fn_prepare, model, features, target, filename):\n",
    "    df_test = fn_prepare(df_test)\n",
    "    df_test[target] = model.predict(df_test[features])\n",
    "    df_test[[target,\"index\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97155c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_features = [\"index\",\"startdate\",\"year\",\"month\",\"day\", \"contest-tmp2m-14d__tmp2m\", \"climateregions__climateregion\"]\n",
    "features = [col for col in df.columns if col not in non_features ]\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4740d74",
   "metadata": {},
   "source": [
    "## Experiment 1 - all features: 1.392\n",
    "Using all the features with one hot encoded climate regions.\n",
    "Observation: \n",
    "- overfitting\n",
    "- need to fix the cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc6e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"metric\": \"mean_squared_error\",\n",
    "    \"num_leaves\": 100,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": 2\n",
    "}\n",
    "scores = train_cv(df, features, target, params, num_boost_round=100, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "final_model = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea6dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(df_test, prepare, final_model, features, target, \"submission1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"feature_importance\": final_model.feature_importance()\n",
    "})\n",
    "features_top15 = df_feature_importance.sort_values(\"feature_importance\", ascending=False).head(15)[\"feature\"].values\n",
    "features_top10 = df_feature_importance.sort_values(\"feature_importance\", ascending=False).head(10)[\"feature\"].values\n",
    "features_top7 = df_feature_importance.sort_values(\"feature_importance\", ascending=False).head(7)[\"feature\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21d0a2",
   "metadata": {},
   "source": [
    "## Experiment 2 - top 10 features: 1.118\n",
    "We haven't fixed the cross validation, but let's try to use only the top10 features from the model from experiment 1.<br>\n",
    "Observation: \n",
    "- Much better score\n",
    "- CV score is much closer to the test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"metric\": \"mean_squared_error\",\n",
    "    \"num_leaves\": 100,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": 1\n",
    "}\n",
    "scores_features_top10 = train_cv(df, features_top10, target, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features_top10]\n",
    "y = df[target]\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "model_features_top10 = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(df_test, prepare, model_features_top10, features_top10, target, \"submission_features_top10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053518e7",
   "metadata": {},
   "source": [
    "## Experiment 3 - top 7 features: 1.455\n",
    "Top 10 features gave quite a big improvement, let's try top 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d885b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features_top7]\n",
    "y = df[target]\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "model_features_top7 = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(df_test, prepare, model_features_top7, features_top7, target, \"submission_features_top7.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb291a4c",
   "metadata": {},
   "source": [
    "# Experiment 4 - top 15 features: 1.1.52\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features_top15]\n",
    "y = df[target]\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "model_features_top15 = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(df_test, prepare, model_features_top15, features_top15, target, \"submission_features_top15.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728550b0",
   "metadata": {},
   "source": [
    "# Experiment 5 - PCA(n_components=5): not submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_weather = PCA(n_components=50)\n",
    "pc_weather = pca_weather.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prepared = prepare(df_test)\n",
    "df_test_pc_weather = pca_weather.transform(df_test_prepared[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[target]\n",
    "train_data = lgb.Dataset(pc_weather, label=y)\n",
    "model_pca5 = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[train_data])\n",
    "df_test[target] = model_pca5.predict(df_test_pc_weather)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wids",
   "language": "python",
   "name": "wids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
